{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning Probabilities by Feature\n",
    "\n",
    "<br>\n",
    "\n",
    "Suppose we have $\\mathbf{x}\\in\\mathbb{R}^m,\\ \\boldsymbol{\\mu}\\in\\mathbb{R}^m,\\text{ and }\\boldsymbol{\\Sigma}\\in\\mathbb{R}^{m,m}$ such that $\\boldsymbol{\\Sigma}^\\text{T}=\\boldsymbol{\\Sigma}$ and the eigen-values of $\\boldsymbol{\\Sigma}$ are all positive.\n",
    "\n",
    "\n",
    "Recall that the log pdf of a multivariate normal to be\n",
    "\n",
    "$$\\begin{align*}\n",
    "    \\log \\text{pdf}(\\mathbf{x}\\ |\\ \\boldsymbol{\\mu},\\ \\boldsymbol{\\Sigma}) \n",
    "    &= -\\frac{m}{2} \\log 2 \\pi - \\frac{1}{2}\\log |\\boldsymbol{\\Sigma}| - \\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu})^\\text{T}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{x} - \\boldsymbol{\\mu}),\n",
    "    & \\big(\\text{use the eigenvalue decomposition } \\mathbf{U}\\mathbf{S}\\mathbf{U}^\\text{T} = \\boldsymbol{\\Sigma}\\big)\\\\\n",
    "    \n",
    "    &= -\\frac{m}{2} \\log 2 \\pi - \\frac{1}{2} \\log |\\mathbf{U}\\mathbf{S}\\mathbf{U}^\\text{T}| - \\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu})^\\text{T}\\mathbf{U}\\mathbf{S}^{-1}\\mathbf{U}^\\text{T}(\\mathbf{x} - \\boldsymbol{\\mu}),\n",
    "    & \\big(|\\mathbf{AB}| = |\\mathbf{A}| \\cdot |\\mathbf{B}| \\text{ and } |\\mathbf{A}| = 1 \\text{ if } \\mathbf{A} \\text{ is orthonormal}\\big)\\\\\n",
    "\n",
    "    &= -\\frac{m}{2} \\log 2 \\pi - \\frac{1}{2} \\log |\\mathbf{S}| - \\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu})^\\text{T}\\mathbf{U}\\mathbf{S}^{-1}\\mathbf{U}^\\text{T}(\\mathbf{x} - \\boldsymbol{\\mu}),\n",
    "    & \\big(\\log |\\mathbf{S}| = \\sum_j^m \\log s_{jj} \\text{ as } \\mathbf{S} \\text{ is a diagonal matrix}\\big)\\\\\n",
    "\n",
    "    &= -\\frac{1}{2}\\sum_j^m \\bigg(\\log 2 \\pi s_{jj} + s_{jj}^{-1}\\big\\langle\\mathbf{x} - \\boldsymbol{\\mu},\\ \\mathbf{u}_{\\cdot,j}\\big\\rangle^2\\bigg).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $\\langle\\cdot,\\ \\cdot\\rangle$ is the inner product and $\\mathbf{u}_{\\cdot,j}$ is the $j$ -th column of $\\mathbf{U}$.<br>\n",
    "\n",
    "$\\therefore -\\frac{1}{2} \\bigg(\\log 2 \\pi s_{jj} + s_{jj}^{-1}\\big\\langle\\mathbf{x} - \\boldsymbol{\\mu},\\ \\mathbf{u}_{\\cdot,j}\\big\\rangle^2\\bigg)$ is the marginalised $\\log$ probability contribution from the $j$-th feature value with respect to all the feature values in the sample.\n",
    "\n",
    "<br>\n",
    "\n",
    "In the case that $\\boldsymbol{\\Sigma}$ is **not symmetric positive definite**, we can use the Singular Value Decomposition to force computations through leading to the alternative more general result:\n",
    "\n",
    "$\\quad -\\frac{1}{2} \\bigg(\\log 2 \\pi s_{jj} + s_{jj}^{-1}\\big\\langle\\mathbf{x} - \\boldsymbol{\\mu},\\ \\mathbf{u}_{\\cdot,j}\\big\\rangle\\langle\\mathbf{x} - \\boldsymbol{\\mu},\\ \\mathbf{v}_{\\cdot,j}\\big\\rangle\\bigg)$\n",
    "\n",
    "where $\\mathbf{USV}^\\text{T} = \\boldsymbol{\\Sigma}$. \n",
    "\n",
    "**Note that $\\mathbf{U} = \\mathbf{V}$ iff $\\boldsymbol{\\Sigma}$ is a symmetric positive definite matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.210372454378047 4.210372454378047\n"
     ]
    }
   ],
   "source": [
    "from   scipy.stats import multivariate_normal\n",
    "import numpy as np\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# no. of features\n",
    "m              = 3\n",
    "\n",
    "# mean and cov\n",
    "mean           = np.random.normal(size = m)\n",
    "temp           = np.random.normal(size = (m ,m))\n",
    "cov            = temp.T @ temp                                     # ensures SPD\n",
    "\n",
    "# define most likely Gaussian distribution that explains the data\n",
    "dist           = multivariate_normal(mean, cov)\n",
    "\n",
    "# random new sample\n",
    "x              = np.random.normal(size = m)\n",
    "\n",
    "# eigenvalues and eigenvectors (orthonormal)\n",
    "U, s, Vt       = np.linalg.svd(cov)\n",
    "V              = Vt.T\n",
    "\n",
    "# negative log likelihood\n",
    "nll            = np.log(2 * np.pi * s).sum() + ((((x - mean) @ U)) * ((x - mean) @ V) / s).sum()\n",
    "nll           /= 2\n",
    "\n",
    "# similar value to scipy's computation\n",
    "print(nll, -dist.logpdf(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.22044605e-16,  1.11022302e-16,  3.33066907e-16],\n",
       "       [ 2.22044605e-16, -1.66533454e-16,  1.11022302e-16],\n",
       "       [-5.55111512e-17, -2.22044605e-16,  1.38777878e-16]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U - V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.09292433 1.50395575 0.61349238]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.210372454378046"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computation for final line in above equation\n",
    "nll_by_feature  = np.log(2 * np.pi * s) + np.square((x - mean) @ U) / s\n",
    "nll_by_feature /= 2\n",
    "\n",
    "print(nll_by_feature)\n",
    "\n",
    "nll_by_feature.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3rd value is the least likely so lets inspect the difference between the sample and the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.00301462, -0.27848219, -0.53487475])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x - mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that $\\mathbf{x}$ is less than $\\boldsymbol{\\mu}$ and that the $x_1$ value is actually the furthest away from the associated $\\mu_1$ value. Lets inspect $\\boldsymbol{\\Sigma}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.09286146,  4.10033934, -1.69091987],\n",
       "       [ 4.10033934,  3.5314304 , -1.60002145],\n",
       "       [-1.69091987, -1.60002145,  3.08063762]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon examining the values, we can see from $\\boldsymbol{\\Sigma}$ that $(x_1 - \\mu_1)$ and $(x_2 - \\mu_2)$ should have the same sign, whereas $(x_3 - \\mu_3)$ should have the opposite sign."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bf0b983d9819a0bb2e9ec68ecfad04eab997f7c5700a7234c04b6d77ff2cc58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
